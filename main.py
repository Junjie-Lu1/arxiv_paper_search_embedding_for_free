from datetime import datetime, timedelta
from config import (DEFAULT_TOPK,
                    DEFAULT_THRESHOLD,
                    DEFAULT_QUERY,
                    DEFAULT_DAYS_TO_SEARCH,
                    DEFAULT_TARGET_TITLE,
                    DEFAULT_TARGET_SUMMARY)
from arxiv_fetch import ArxivPaperSearcher
from computer_embedding import get_paper_by_embedding, initialize_model

def main():
    
    # æ„å»ºå¸¦æ—¶é—´èŒƒå›´çš„æŸ¥è¯¢
    end_date = datetime.utcnow().strftime('%Y%m%d')
    start_date = (datetime.utcnow() - timedelta(days=DEFAULT_DAYS_TO_SEARCH)).strftime('%Y%m%d')
    query = f"{DEFAULT_QUERY} AND submittedDate:[{start_date} TO {end_date}]"

    print("=" * 60)
    print(f"ğŸš€ å¼€å§‹æ£€ç´¢ arXiv ä¸Šæœ€è¿‘ {DEFAULT_DAYS_TO_SEARCH} å¤©çš„è®ºæ–‡...")
    print(f"ğŸ” æŸ¥è¯¢è¯­å¥: {query}")
    print("=" * 60)

    searcher = ArxivPaperSearcher(query=query)

    # åŠ è½½æ¨¡å‹ï¼ˆæå‰åŠ è½½ï¼Œé¿å…åé¢å¡é¡¿ï¼‰
    print("\nğŸ§  æ­£åœ¨åŠ è½½è¯­ä¹‰æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ï¼‰...")
    model = initialize_model()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆã€‚\n")

    print("è¯·é€‰æ‹©ä½ çš„æ¨¡å¼ï¼š\n")
    print("1. åˆ†æ‰¹æ¬¡è·å–")
    print("2. ä¸€æ¬¡æ€§è·å–")
    decision =  input("\nè¯·åšå‡ºé€‰æ‹© (1/2): ").strip()
    if decision == '1': # æ³¨æ„ä¸æ˜¯1è€Œæ˜¯'1'
        # äº¤äº’ä¸»å¾ªç¯
        while True:
            total = searcher.get_total_count()
            next_start = searcher.current_start
            next_end = next_start + searcher.max_results_per_batch

            print(f"\nğŸ“Š å½“å‰å·²ç¼“å­˜è®ºæ–‡æ•°é‡: {total}")
            print(f"ğŸ“¥ ä¸‹ä¸€æ‰¹å°†è·å–è®ºæ–‡ç´¢å¼•èŒƒå›´: [{next_start} ~ {next_end})")
            print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
            print("1. è·å–ä¸‹ä¸€æ‰¹è®ºæ–‡")
            print("2. åŸºäºå½“å‰æ‰€æœ‰è®ºæ–‡è¿›è¡Œç›¸ä¼¼åº¦æœç´¢")
            print("3. é€€å‡º")

            choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3): ").strip() # stripæŠŠæ— å…³å­—ç¬¦æ»¤æ‰ï¼Œåªå…³æ³¨é€‰é¡¹æ•°å­—

            if choice == '1':
                print(f"\nâ³ æ­£åœ¨è·å–ç¬¬ [{next_start} ~ {next_end}) ç¯‡è®ºæ–‡...")
                batch_papers, _ = searcher.get_next_batch()

                if not batch_papers:
                    print("ğŸ“Œ æœ¬æ¬¡æœªè·å–åˆ°æ–°è®ºæ–‡ï¼ˆå¯èƒ½å·²åˆ°æœ«å°¾ï¼‰")
                else:
                    print(f"âœ… æˆåŠŸè·å– {len(batch_papers)} ç¯‡æ–°è®ºæ–‡ï¼")
                    print(f"ğŸ“š å½“å‰æ€»è®ºæ–‡æ•°: {searcher.get_total_count()}")

            elif choice == '2':
                if searcher.get_total_count() == 0:
                    print("â— è¯·å…ˆè·å–è‡³å°‘ä¸€æ‰¹è®ºæ–‡å†è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ã€‚")
                    continue

                print(f"\nğŸ” æ­£åœ¨å¯¹ {searcher.get_total_count()} ç¯‡è®ºæ–‡è¿›è¡Œè¯­ä¹‰åŒ¹é…...")
                results = get_paper_by_embedding(model = model, all_papers_list = searcher.all_papers_list, target_title = DEFAULT_TARGET_TITLE, target_summary = DEFAULT_TARGET_SUMMARY)

                if not results:
                    print(f"âŒ æœªæ‰¾åˆ°ç›¸ä¼¼åº¦ â‰¥ {DEFAULT_THRESHOLD} çš„è®ºæ–‡ã€‚")
                else:
                    print(f"\nâœ… æ‰¾åˆ° {len(results)} ç¯‡é«˜åº¦ç›¸ä¼¼(ç›¸ä¼¼åº¦å¤§äº{DEFAULT_THRESHOLD})çš„è®ºæ–‡ï¼ˆTop-{DEFAULT_TOPK}ï¼‰ï¼š\n")
                    for rank, (idx, sim) in enumerate(results, 1): # åŠ ä¸Š1ï¼Œä»1å¼€å§‹ç¼–å·
                        paper = searcher.all_papers_list_dict[idx]
                        print(f"ã€{rank}ã€‘ç›¸ä¼¼åº¦: {sim:.4f}")
                        print(f"æ ‡é¢˜: {paper['title']}")
                        print(f"æ‘˜è¦: {paper['summary']}")
                        print("-" * 80)

            elif choice == '3':
                print("ğŸ‘‹ ç¨‹åºå·²é€€å‡ºï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
                break

            else:
                print("â— æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3ã€‚")
    elif decision == '2':
            # è‡ªåŠ¨è·å–æ‰€æœ‰è®ºæ–‡ï¼ˆæœ€å¤š 10,000 ç¯‡ï¼‰
        print("\nâ³ æ­£åœ¨è‡ªåŠ¨ä¸‹è½½è®ºæ–‡ï¼ˆè¯·è€å¿ƒç­‰å¾…ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...\n")
        current_count = 0
        current_count_repeat = 0
        while True:
            prev_count = searcher.get_total_count()
            batch = searcher.get_next_batch()
            last_current_count = current_count
            current_count = searcher.get_total_count()
            if not batch:
                break
            print(f"âœ… å·²è·å– {current_count} ç¯‡è®ºæ–‡...")
            if current_count == last_current_count:
                current_count_repeat += 1
                if current_count_repeat > 5:
                    break
            else:
                current_count_repeat = 0

        total = searcher.get_total_count()
        if total == 0:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•è®ºæ–‡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–è°ƒæ•´æ—¶é—´èŒƒå›´ã€‚")
            return

        print(f"\nğŸ‰ æˆåŠŸè·å– {total} ç¯‡è®ºæ–‡ï¼\n")

        # ç›¸ä¼¼åº¦æœç´¢
        print("\nğŸ” æ­£åœ¨è¿›è¡Œç›¸ä¼¼åº¦åŒ¹é…...")
        results = get_paper_by_embedding(model, searcher.all_papers_list, target_title = DEFAULT_TARGET_TITLE, target_summary = DEFAULT_TARGET_SUMMARY)
        # è¾“å‡ºç»“æœ
        if not results:
            print(f"âŒ æœªæ‰¾åˆ°ç›¸ä¼¼åº¦ â‰¥ {DEFAULT_THRESHOLD} çš„è®ºæ–‡ã€‚")
        else:
            print(f"\nâœ… æ‰¾åˆ° {len(results)} ç¯‡é«˜åº¦ç›¸ä¼¼çš„è®ºæ–‡ï¼ˆTop-{DEFAULT_TOPK}ï¼‰ï¼š\n")
            for rank, (idx, sim) in enumerate(results, 1):
                paper = searcher.all_papers_list_dict[idx]
                print(f"ã€{rank}ã€‘ç›¸ä¼¼åº¦: {sim:.4f}")
                print(f"æ ‡é¢˜: {paper['title']}")
                print(f"æ‘˜è¦: {paper['summary']}")
                print("-" * 80)

        print("\nğŸ”š ç¨‹åºè¿è¡Œå®Œæ¯•ï¼")
    else:
        print("â— æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1 æˆ– 2ã€‚")


if __name__ == "__main__":
    main()